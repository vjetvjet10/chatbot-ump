# from agents.router_agent import route_query
# from agents.faq_agent import search_faq
# from agents.retriever_agent import retrieve_documents
# from agents.responder_agent import generate_response
# from agents.followup_agent import suggest_followups
# # from agents.document_agent import process_all_documents
# import json
# import asyncio
# async def query_pipeline(user_query: str, websocket) -> dict:
#     # Æ¯u tiÃªn tÃ¬m trong FAQ
#     answer = search_faq(user_query)
#     if answer:
#         for token in answer:
#             await websocket.send_text(json.dumps({"stream":token}, ensure_ascii=False))
#             await asyncio.sleep(0.01) #giáº£ láº­p delay nhá»
#             await websocket.send_text("[END]")
#         # return {
#         #     "answer": answer,
#         #     "sources": [{"source": "faq.xlsx", "highlight": answer}],
#         #     "suggestions": []
#         # }
#         return {
#     "sources": [{"source": "faq.xlsx", "highlight": answer}],
#     "suggestions": []
# }

#     # Tuá»³ chá»n: náº¡p láº¡i tÃ i liá»‡u náº¿u cáº§n
#     # process_all_documents()
#     # run_document_processing
#     # 2) XÃ¡c Ä‘á»‹nh domain: dao_tao hoáº·c ctsv
#     domain = route_query(user_query)
#     print(f"ğŸ§  DOMAIN: {domain}")

#     # 3) Láº¥y tÃ i liá»‡u liÃªn quan
#     docs = retrieve_documents(user_query, domain)
#     print(f"ğŸ“„ DOCS RETRIEVED: {len(docs)}")

#     # 4) Gá»i generate_response vá»›i Ä‘á»§ 4 arg
#     answer = await generate_response(user_query, docs, websocket, domain)
#     print(f"ğŸ“¬ ANSWER: {answer}")

#     # 5) Gá»£i Ã½ followâ€‘up
#     suggestions = suggest_followups(user_query, answer, domain)

#     # return {
#     #     # "answer": answer,
#     #     "sources": [doc.metadata for doc in docs],
#     #     "suggestions": suggestions
#     # }
#         # âœ… Sau khi stream xong, chá»‰ gá»­i láº¡i sources/suggestions (khÃ´ng gá»­i láº¡i answer)
#     await websocket.send_text(json.dumps({
#         "type": "metadata",
#         "sources": [doc.metadata for doc in docs],
#         "suggestions": suggestions
#     }, ensure_ascii=False))

#     return {}
from langchain_core.documents import Document
from agents.router_agent import route_query
from agents.faq_agent import search_faq
from agents.retriever_agent import retrieve_documents
from agents.responder_agent import generate_response
from agents.followup_agent import suggest_followups
import json
import asyncio
from agents.web_search_agent import search_google_ump, extract_text_from_url
def truncate_docs(docs, max_tokens=4000):
    result = []
    total_tokens = 0
    for d in docs:
        tokens = len(d.page_content) // 4  # xáº¥p xá»‰
        if total_tokens + tokens > max_tokens:
            break
        result.append(d)
        total_tokens += tokens
    return result
def needs_fallback(answer: str) -> bool:
    """PhÃ¡t hiá»‡n cÃ¢u tráº£ lá»i quÃ¡ chung chung / khÃ´ng cÃ³ dá»¯ liá»‡u"""
    signals = [
        "khÃ´ng cÃ³ sá»‘ liá»‡u", "chÆ°a cÃ³ sá»‘ liá»‡u", "khÃ´ng tÃ¬m tháº¥y", "vui lÃ²ng tra cá»©u", "khÃ´ng rÃµ", 
        "chÆ°a cÃ³ thÃ´ng tin", "khÃ´ng cÃ³ thÃ´ng tin","dá»¯ liá»‡u","trong cÃ¡c Ä‘oáº¡n trÃ­ch","khÃ´ng cÃ³ trong cÃ¡c tÃ i liá»‡u Ä‘Æ°á»£c cung cáº¥p"
    ]
    return any(kw in answer.lower() for kw in signals)


async def fallback_web_search(query: str) -> list[str]:
    urls = search_google_ump(query)
    docs = [extract_text_from_url(url) for url in urls]
    return docs
async def query_pipeline(user_query: str, websocket, history: list = None) -> dict:
    answer = search_faq(user_query)
    if answer:
        for token in answer:
            await websocket.send_text(json.dumps({"stream":token}, ensure_ascii=False))
            await asyncio.sleep(0.01)
        await websocket.send_text("[END]")
        return {
            "sources": [{"source": "faq.xlsx", "highlight": answer}],
            "suggestions": []
        }

    domain = route_query(user_query)
    print(f"ğŸ§  DOMAIN: {domain}")

    docs = retrieve_documents(user_query, domain)
    print(f"ğŸ“„ DOCS RETRIEVED: {len(docs)}")

    answer, highlights = await generate_response(user_query, docs, websocket, domain, history)
    # answer, = await generate_response(user_query, docs, websocket, domain)
    print(f"ğŸ“¬ ANSWER (Internal): {answer}")
    # 5ï¸âƒ£ Náº¿u cÃ¢u tráº£ lá»i khÃ´ng chá»©a thÃ´ng tin â†’ fallback web
    if needs_fallback(answer):
        print("âš ï¸ Tráº£ lá»i khÃ´ng Ä‘á»§ thÃ´ng tin â†’ fallback web")
            # âœ… Gá»­i tÃ­n hiá»‡u clear cho frontend trÆ°á»›c khi báº¯t Ä‘áº§u search
        await websocket.send_text(json.dumps({"type": "replace_ai_message","new_answer": ""}, ensure_ascii=False))
        urls = search_google_ump(user_query)
        web_docs = []
        for url in urls:
            text = extract_text_from_url(url)
            if text:
                web_docs.append(Document(page_content=text, metadata={"source": url}))
        if web_docs:
            web_docs = truncate_docs(web_docs, max_tokens=3000)
        answer, highlights = await generate_response(user_query, web_docs, websocket, domain, history)
    # answer, = await generate_response(user_query, docs, websocket, domain)
        print(f"ğŸ“¬ ANSWER: {answer}")
                    # ğŸ‘‰ Gá»­i láº¡i cÃ¢u tráº£ lá»i Ä‘Ã£ cáº­p nháº­t tá»« web
        await websocket.send_text(json.dumps({
            "type": "replace_ai_message",
            "new_answer": answer
        }, ensure_ascii=False))

        # âœ… Step 3: Sau táº¥t cáº£, gá»­i [END]
    await websocket.send_text("[END]")
    suggestions = suggest_followups(user_query, answer, domain)

    await websocket.send_text(json.dumps({
        "type": "metadata",
        "sources": highlights,
        "suggestions": suggestions
    }, ensure_ascii=False))

    return {}




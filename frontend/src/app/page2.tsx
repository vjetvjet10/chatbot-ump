// 'use client'

// import { useState, useEffect, useRef } from 'react'
// import dynamic from 'next/dynamic'
// import { PaperAirplaneIcon, MicrophoneIcon, DocumentIcon } from '@heroicons/react/24/solid'

// const PdfPreview = dynamic(() => import('../components/PdfPreview'), { ssr: false })

// interface Message {
//   role: 'user' | 'assistant'
//   content: string
// }
// interface SourceGroup {
//   source: string
//   highlights: string[]
// }

// export default function Home() {
//   const [messages, setMessages] = useState<Message[]>([])
//   const [input, setInput] = useState("")
//   const [sources, setSources] = useState<SourceGroup[]>([])
//   const [suggestions, setSuggestions] = useState<string[]>([])
//   const [isTyping, setIsTyping] = useState(false)
//   const [typingDots, setTypingDots] = useState("")
//   const [sidebarOpen, setSidebarOpen] = useState(false)
//   const [showAllHighlights, setShowAllHighlights] = useState(false)
//   const [isRecording, setIsRecording] = useState(false)
//   const [showViewer, setShowViewer] = useState(false)
//   const [isFirstLoad, setIsFirstLoad] = useState(true);
//   const maxHighlights = 5
//   const socketRef = useRef<WebSocket | null>(null)
//   const mediaRecorderRef = useRef<MediaRecorder | null>(null)
//   const audioChunksRef = useRef<Blob[]>([])
//   const inputRef = useRef<HTMLTextAreaElement>(null)
//   const bottomRef = useRef<HTMLDivElement | null>(null)
//   const currentAssistantMessageRef = useRef<string>("") // Th√™m ref n√†y

//   const toggleSidebar = () => setSidebarOpen(prev => !prev)

//   useEffect(() => {
//     const socket = new WebSocket(`ws://${window.location.hostname}:8000/chat`)
//     socketRef.current = socket
//     socket.onmessage = (event) => {
//       // --- B·∫ÆT ƒê·∫¶U DEBUG ---
//       // Lu√¥n log d·ªØ li·ªáu th√¥ nh·∫≠n ƒë∆∞·ª£c ƒë·ªÉ ch·∫Øc ch·∫Øn backend kh√¥ng g·ª≠i l·∫∑p
//       console.log("Raw WebSocket Data:", event.data);
//       // --- K·∫æT TH√öC DEBUG ---

//       if (event.data === "[END]") {
//         setIsTyping(false)
//         currentAssistantMessageRef.current = ""; // Reset ref khi k·∫øt th√∫c
//         return
//       }

//       let data: any;
//       try {
//         data = JSON.parse(event.data);
//       } catch {
//         // N·∫øu kh√¥ng ph·∫£i JSON (v√≠ d·ª•: blob √¢m thanh), b·ªè qua ph·∫ßn x·ª≠ l√Ω JSON
//         // Quan tr·ªçng: ƒê·∫£m b·∫£o kh√¥ng c√≥ d·ªØ li·ªáu text n√†o b·ªã b·ªè l·ª° n·∫øu backend g·ª≠i text kh√¥ng ph·∫£i JSON
//         console.log("Non-JSON message received:", event.data);
//         return;
//       }

//       // --- X·ª¨ L√ù STREAMMING ƒê√É S·ª¨A ---
//       if (data.stream) {
//         // 1. N·ªëi chunk m·ªõi v√†o ref
//         currentAssistantMessageRef.current += data.stream;

//         // 2. C·∫≠p nh·∫≠t state messages
//         setMessages(prev => {
//           const updated = [...prev];
//           if (updated.length === 0 || updated[updated.length - 1]?.role !== 'assistant') {
//             // B·∫Øt ƒë·∫ßu tin nh·∫Øn m·ªõi: ƒê·∫∑t n·ªôi dung l√† to√†n b·ªô ref hi·ªán t·∫°i
//             updated.push({ role: 'assistant', content: currentAssistantMessageRef.current.trimStart() });
//           } else {
//             // C·∫≠p nh·∫≠t tin nh·∫Øn cu·ªëi: G√°n b·∫±ng to√†n b·ªô n·ªôi dung ref hi·ªán t·∫°i
//             updated[updated.length - 1].content = currentAssistantMessageRef.current;
//           }
//           return updated;
//         });
//       }
//       // --- K·∫æT TH√öC S·ª¨A STREAMING ---

//       else if (data.type === 'replace_ai_message') {
//         // Khi thay th·∫ø to√†n b·ªô, c≈©ng c·∫≠p nh·∫≠t ref
//         currentAssistantMessageRef.current = data.new_answer.trim();
//         setMessages(prev => {
//           const last = prev[prev.length - 1];
//           if (last?.role === 'assistant') {
//             // Thay th·∫ø tin nh·∫Øn cu·ªëi
//             return [...prev.slice(0, -1), { role: 'assistant', content: currentAssistantMessageRef.current }];
//           } else {
//             // Th√™m tin nh·∫Øn m·ªõi n·∫øu kh√¥ng c√≥ tin nh·∫Øn assistant ·ªü cu·ªëi
//             return [...prev, { role: 'assistant', content: currentAssistantMessageRef.current }];
//           }
//         });
//         // C√≥ th·ªÉ c·∫ßn reset isTyping n·∫øu replace_ai_message l√† d·∫•u hi·ªáu k·∫øt th√∫c
//         // setIsTyping(false); // Xem x√©t logic backend c·ªßa b·∫°n
//       }

//       else if (data.type === 'metadata') {
//         // X·ª≠ l√Ω metadata kh√¥ng ƒë·ªïi...
//         const grouped = new Map<string, string[]>()
//         for (const s of data.sources || []) {
//           const file = String(s.source)
//           const highlight = s.highlight || ""
//           if (!grouped.has(file)) grouped.set(file, [highlight])
//           else grouped.get(file)!.push(highlight)
//         }
//         const groupedArray = Array.from(grouped.entries()).map(([source, highlights]) => ({ source, highlights }))
//         setSources(groupedArray)
//         if (data.suggestions) setSuggestions(data.suggestions)
//       }

//       else if (data.type === 'recognized_text') {
//         // DEBUG: Xem backend g·ª≠i g√¨
//         console.log('Received recognized_text data:', data);
    
//         // Gi·∫£ s·ª≠ backend ƒë√£ ƒë∆∞·ª£c s·ª≠a v√† data.text ch·ª©a b·∫£n ghi gi·ªçng n√≥i th√¥
//         const recognized = data.text.trim();
    
//         // --- T·ª∞ ƒê·ªòNG G·ª¨I KHI C√ì K·∫æT QU·∫¢ NH·∫¨N D·∫†NG ---
//         if (recognized && socketRef.current && socketRef.current.readyState === WebSocket.OPEN) {
//           // 1. Th√™m tin nh·∫Øn User v√†o messages ngay l·∫≠p t·ª©c
//           const newMessages = [...messages, { role: 'user', content: recognized }];
//           setMessages(newMessages);
    
//           // 2. Chu·∫©n b·ªã v√† g·ª≠i payload t·ªõi backend
//           const payload = {
//             query: recognized,
//             // L·∫•y l·ªãch s·ª≠ BAO G·ªíM c·∫£ tin nh·∫Øn user v·ª´a th√™m
//             history: newMessages.slice(-4)
//           };
//           socketRef.current.send(JSON.stringify(payload));
    
//           // 3. ƒê·∫∑t tr·∫°ng th√°i ƒëang ch·ªù AI tr·∫£ l·ªùi
//           setIsTyping(true);
    
//           // 4. X√≥a n·ªôi dung √¥ input (v√¨ ƒë√£ g·ª≠i)
//           setInput("");
//           // Reset chi·ªÅu cao textarea n·∫øu c·∫ßn
//           if (inputRef.current) {
//               inputRef.current.style.height = 'auto';
//           }
    
//           // 5. Reset c√°c state kh√°c nh∆∞ sources, suggestions
//           setSources([]);
//           setSuggestions([]);
//           currentAssistantMessageRef.current = ""; // Reset n·ªôi dung AI ƒëang x√¢y d·ª±ng
    
//         } else if (recognized) {
//            // Ch·ªâ c·∫≠p nh·∫≠t input n·∫øu c√≥ text nh∆∞ng socket kh√¥ng s·∫µn s√†ng
//            setInput(recognized);
//            if (inputRef.current) {
//              inputRef.current.style.height = 'auto';
//              inputRef.current.style.height = `${inputRef.current.scrollHeight}px`;
//            }
//            inputRef.current?.focus();
//         } else {
//            // X·ª≠ l√Ω tr∆∞·ªùng h·ª£p kh√¥ng nh·∫≠n d·∫°ng ƒë∆∞·ª£c g√¨ (recognized r·ªóng)
//            console.log("Recognition returned empty text.");
//            // C√≥ th·ªÉ hi·ªÉn th·ªã th√¥ng b√°o nh·ªè ho·∫∑c kh√¥ng l√†m g√¨ c·∫£
//         }
//       }
//       if (data.final) {
//         setIsTyping(false)
//       }

//     //   if (data.error) {
//     //     setMessages(prev => [...prev, { role: 'assistant', content: `‚ùå L·ªói: ${data.error}` }])
//     //     setIsTyping(false)
//     //   }
//     // }
//     else if (data.error) {
//       setMessages(prev => [...prev, { role: 'assistant', content: `‚ùå L·ªói: ${data.error}` }])
//       setIsTyping(false)
//       currentAssistantMessageRef.current = ""; // Reset ref khi c√≥ l·ªói
//     }
//   }

//     socket.onclose = () => setIsTyping(false)

//     return () => socket.close()
//   }, [])

// // Quan tr·ªçng: Reset ref khi g·ª≠i tin nh·∫Øn m·ªõi
//     const handleSubmit = () => {
//       if (!input.trim() || !socketRef.current) return
//       setIsFirstLoad(false);
//       const question = input.trim()

//       const updatedMessages = [...messages, { role: 'user', content: question }]
//       setMessages(updatedMessages)

//       const payload = {
//         query: question,
//         history: updatedMessages.slice(-4) // G·ª≠i l·ªãch s·ª≠ *tr∆∞·ªõc khi* AI tr·∫£ l·ªùi
//       }

//       socketRef.current.send(JSON.stringify(payload))
//       setInput("")
//       // Reset chi·ªÅu cao textarea
//       if (inputRef.current) {
//           inputRef.current.style.height = 'auto';
//       }
//       setIsTyping(true)
//       setSources([])
//       setSuggestions([])
//       inputRef.current?.focus()
//       currentAssistantMessageRef.current = ""; // <-- RESET REF ·ªû ƒê√ÇY
//     }

//   const startRecording = async () => {
//     if (typeof window === 'undefined' || !navigator.mediaDevices) {
//       console.error("üéôÔ∏è Recording not supported")
//       return
//     }
//     const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
//     const mediaRecorder = new MediaRecorder(stream)
//     mediaRecorderRef.current = mediaRecorder
//     audioChunksRef.current = []

//     mediaRecorder.ondataavailable = (e) => {
//       audioChunksRef.current.push(e.data)
//     }

//     mediaRecorder.onstop = async () => {
//       const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' })
//       if (socketRef.current?.readyState === WebSocket.OPEN) {
//         socketRef.current.send(audioBlob)
//       }
//     }

//     mediaRecorder.start()
//     setIsRecording(true)
//   }

//   const stopRecording = () => {
//     if (mediaRecorderRef.current?.state === "recording") {
//       mediaRecorderRef.current.stop()
//       setIsRecording(false)
//     }
//   }

//   useEffect(() => {
//     if (!isTyping) return
//     const interval = setInterval(() => {
//       setTypingDots(prev => (prev.length >= 3 ? "" : prev + "."))
//     }, 500)
//     return () => clearInterval(interval)
//   }, [isTyping])

//   useEffect(() => {
//     bottomRef.current?.scrollIntoView({ behavior: 'smooth' })
//   }, [messages, isTyping])